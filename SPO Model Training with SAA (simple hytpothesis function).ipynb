{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ba30d1-2298-4028-8486-58e8acf8a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4d2f0a-5712-4b08-b80c-a6cea8ff53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1342fc3-6d7c-4f3e-910c-ba3057bf05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a0debb-dad4-4976-9a1e-54975dd5266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e401614d-60a1-4589-ace8-049956d27ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35273, 84)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_preprocessed_(19-25).csv\")\n",
    "data.shape\n",
    "data['DecisiontoTreatDate'] = pd.to_datetime(data['DecisiontoTreatDatetime'], errors = 'coerce')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbfe90-2652-49bc-ab3d-408436e03bc3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26607dc9-a139-41d6-ae9e-28e94c9da31f",
   "metadata": {},
   "source": [
    "#### For now, to make the problem easier, we only select a subset of surgeons for consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d92536c-4ef6-420d-b4ef-f455cd16ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "data_24_25 = data[\n",
    "    (data['ScheduledDate'] >= '2024-07-01') &\n",
    "    (data['ScheduledDate'] < '2025-01-01')\n",
    "].copy()\n",
    "\n",
    "list_24_25 = data_24_25['surgeonID'].value_counts().index.tolist()\n",
    "\n",
    "counts = data[data['surgeonID'].isin(list_24_25)]['surgeonID'].value_counts()\n",
    "surgeons_list = counts[counts > 100].index.tolist()\n",
    "data =  data[data['surgeonID'].isin(surgeons_list)]\n",
    "print(len(surgeons_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647aa762-6d04-408b-80ad-1572fcece63d",
   "metadata": {},
   "source": [
    "#### Let use build some number of reward classes, rewward class indexed by (Specialty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944b8d48-2d96-415e-863c-f22f58d7a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 15\n",
    "ratio = data['Weighted_Case'] / data['book_dur']\n",
    "r_pct = ratio.rank(method='first', pct=True)              # unique in (0,1]\n",
    "data['Reward_Group'] = np.ceil(r_pct * n_classes)         # 1..n_classes\n",
    "data['Reward_Group'] = data['Reward_Group'].clip(1, n_classes).astype(int)\n",
    "\n",
    "# Everything else stays the same\n",
    "data['reward_value'] = ratio\n",
    "group_means = (\n",
    "    data.groupby('Reward_Group', as_index=False)['reward_value']\n",
    "        .mean()\n",
    "        .rename(columns={'reward_value': 'mean_reward'})\n",
    ")\n",
    "reward_lookup = dict(zip(group_means['Reward_Group'], group_means['mean_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37065ba1-073d-41e8-baae-5434540a304c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "per_surgeon_counts = (\n",
    "    data.dropna(subset=['Reward_Group'])\n",
    "        .groupby('surgeonID')['Reward_Group']\n",
    "        .nunique()\n",
    "        .rename('n_distinct_groups')\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "per_surgeon_lists = (\n",
    "    data.dropna(subset=['Reward_Group'])\n",
    "        .groupby('surgeonID')['Reward_Group']\n",
    "        .apply(lambda x: sorted(x.unique().tolist()))\n",
    "        .rename('groups_present')\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "per_surgeon_summary = per_surgeon_counts.merge(per_surgeon_lists, on='surgeonID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "914a0ff7-4f7c-42f9-bdd5-bb7b502e2c61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# specialty loop_up\n",
    "mode_cat = (\n",
    "    data.groupby('surgeonID')['SERVICE_CATEGORY']\n",
    "        .agg(lambda x: x.mode().iloc[0])\n",
    ")\n",
    "specialty_lookup = dict(mode_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727ac67c-c304-42f2-a949-dd092cc8b942",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Duration calculation:\n",
    "specialties = sorted(data['SERVICE_CATEGORY'].unique().tolist())\n",
    "groups = sorted(data['Reward_Group'].unique().tolist()) \n",
    "pivot = (data\n",
    "         .groupby(['SERVICE_CATEGORY', 'Reward_Group'])['book_dur']\n",
    "         .mean()\n",
    "         .unstack('Reward_Group'))\n",
    "\n",
    "global_mean = data['book_dur'].mean()\n",
    "pivot = pivot.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "pivot = pivot.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "pivot = pivot.fillna(global_mean)\n",
    "pivot = pivot.reindex(index=specialties, columns=groups, fill_value=global_mean)\n",
    "tau_nom_sc = pivot.to_numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a480f01-d30d-4b3f-980a-1eafc348bc27",
   "metadata": {},
   "source": [
    "### Constructing SAA scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a042388b-d138-4838-b00b-754845249aaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_arrival_scenarios_by_surgeon(\n",
    "    training_raw: pd.DataFrame,\n",
    "    *,\n",
    "    surgeons_list,\n",
    "    surgeon_col: str = \"surgeonID\",\n",
    "    date_col: str = \"DecisiontoTreatDate\",\n",
    "    reward_col: str = \"Reward_Group\",\n",
    "    n_scenarios: int = 20,\n",
    "    T: int = 8,\n",
    "    week_anchor: str = \"W-MON\",\n",
    "    C: int | None = None,\n",
    "    random_state: int | None = 42\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df = training_raw.copy()\n",
    "    df[\"week_start\"] = df[date_col].dt.to_period(week_anchor).dt.start_time\n",
    "\n",
    "    weekly_wide = (\n",
    "        df.groupby([surgeon_col, \"week_start\", reward_col])\n",
    "          .size().rename(\"arrivals\").reset_index()\n",
    "          .pivot_table(index=[surgeon_col, \"week_start\"],\n",
    "                       columns=reward_col,\n",
    "                       values=\"arrivals\",\n",
    "                       fill_value=0)\n",
    "          .sort_index()\n",
    "    )\n",
    "    # Surgeon index\n",
    "    surgeons = surgeons_list\n",
    "    N = len(surgeons)\n",
    "    sid_to_idx = surgeon_to_idx\n",
    "    idx_to_sid = np.asarray(surgeons)  \n",
    "    # Reward classes normalization to 0..C-1\n",
    "    present_classes = set(weekly_wide.columns.tolist())\n",
    "        \n",
    "    full_classes = list(range(1, C + 1))\n",
    "    for r in full_classes:\n",
    "        if r not in weekly_wide.columns:\n",
    "            weekly_wide[r] = 0\n",
    "    weekly_wide = weekly_wide.reindex(columns=full_classes, fill_value=0)\n",
    "\n",
    "    # Bootstrap T weeks per surgeon, K scenarios\n",
    "    K = n_scenarios\n",
    "    A = np.zeros((K, N, C, T), dtype=int)\n",
    "    records = []\n",
    "    grouped = dict(tuple(weekly_wide.groupby(level=0)))\n",
    "    for k in range(K):\n",
    "        for sid in surgeons:\n",
    "            sidx = sid_to_idx[sid]\n",
    "            if sid in grouped:\n",
    "                block = grouped[sid]\n",
    "                X = block.droplevel(0).to_numpy(int)\n",
    "                n_hist = X.shape[0]\n",
    "                if n_hist > 0:\n",
    "                    idx = rng.integers(0, n_hist, size=T)\n",
    "                    sampled = X[idx, :]\n",
    "                else:\n",
    "                    sampled = np.zeros((T, C), int)\n",
    "            else:\n",
    "                sampled = np.zeros((T, C), int)\n",
    "\n",
    "            A[k, sidx, :, :] = sampled.T\n",
    "            for t in range(T):\n",
    "                for c in range(C):\n",
    "                    records.append({\n",
    "                        \"scenario\": k + 1,\n",
    "                        surgeon_col: sid,\n",
    "                        \"week\": t + 1,\n",
    "                        reward_col: c,\n",
    "                        \"arrivals\": int(sampled[t, c])\n",
    "                    })\n",
    "\n",
    "    scen_long = pd.DataFrame.from_records(records)\n",
    "    return scen_long, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ebb9ba7-40f7-412e-a59e-b0bdf7137999",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_backlog_individual_at_t0(\n",
    "    df,\n",
    "    t0,\n",
    "    group_cols=('surgeonID',),                 # keep for later aggregation\n",
    "    reward_col='Reward_Group',\n",
    "    arrival_date_col='DecisiontoTreatDate',\n",
    "    treated_date_col='ScheduledDate',            # None if unavailable\n",
    "    cancel_col=None, cancel_values=None,       # e.g., {'Cancelled','NoShow'}\n",
    "    feature_cols=(\n",
    "        'Patient_Gender_Binary', 'DecisionYear', 'DecisionMonth', 'DecisionDay',\n",
    "        'DecisionWeekday', 'PatientType_encoded', 'Case Mix Group_encoded',\n",
    "        'Diagnosis1_encoded', 'ProcedureMnemonic_encoded'),\n",
    "):\n",
    "    cols = list(group_cols) + [reward_col, arrival_date_col] + list(feature_cols)\n",
    "    if treated_date_col and treated_date_col not in cols:\n",
    "        cols.append(treated_date_col)\n",
    "    if cancel_col and cancel_col not in cols:\n",
    "        cols.append(cancel_col)\n",
    "\n",
    "    use = df[cols].copy()\n",
    "    use[arrival_date_col] = pd.to_datetime(use[arrival_date_col], errors='coerce')\n",
    "    if treated_date_col:\n",
    "        use[treated_date_col] = pd.to_datetime(use[treated_date_col], errors='coerce')\n",
    "\n",
    "    # \"Waiting at t0\": arrived on/before t0, and not treated by t0, and not cancelled\n",
    "    mask = use[arrival_date_col].le(t0)\n",
    "    if treated_date_col:\n",
    "        mask &= (use[treated_date_col].isna() | use[treated_date_col].gt(t0))\n",
    "    if cancel_col and cancel_values:\n",
    "        mask &= ~use[cancel_col].isin(cancel_values)\n",
    "\n",
    "    cases = use.loc[mask].dropna(subset=list(group_cols) + [reward_col])\n",
    "    return cases.reset_index(drop=True)\n",
    "\n",
    "def backlog_counts_at_t0(cases_t0, group_cols=('surgeonID',), reward_col='Reward_Group', n_rewards=20):\n",
    "    tbl = (cases_t0.groupby(list(group_cols) + [reward_col])\n",
    "                  .size()\n",
    "                  .unstack(fill_value=0))\n",
    "    for r in range(1, n_rewards + 1):\n",
    "        if r not in tbl.columns:\n",
    "            tbl[r] = 0\n",
    "    tbl = tbl[[r for r in range(1, n_rewards + 1)]]\n",
    "    tbl.columns = [f'y_r{r}' for r in range(1, n_rewards + 1)]\n",
    "    tbl['Total_Waiting'] = tbl.sum(axis=1)\n",
    "    return tbl.reset_index()\n",
    "\n",
    "def counts_df_to_dict(counts_df, group_col='surgeonID', n_rewards=20, keep_zeros=False):\n",
    "    d = {}\n",
    "    for _, row in counts_df.iterrows():\n",
    "        sid = row[group_col]\n",
    "        for r in range(1, n_rewards+1):\n",
    "            cnt = int(row[f'y_r{r}'])\n",
    "            if keep_zeros or cnt > 0:\n",
    "                d[(sid, r)] = cnt\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f529f1-6554-4b0a-a37f-9a7cd8f72f15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c551c93b-be27-4e33-980d-f0ec0f0bfa34",
   "metadata": {},
   "source": [
    "### Building Initial Waitlists Samples, these are ones with feature informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24860669-f725-46e9-92a9-f2ca41d02d5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3804a7a8-212a-4800-8720-78101ba7d0d0",
   "metadata": {},
   "source": [
    "#### Constructing the Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ddf0d1-6d57-42f7-8475-c454ac1227d6",
   "metadata": {},
   "source": [
    "#### Implementing the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbda3dbc-ebb3-484e-a481-c6be42a86210",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "C = 15\n",
    "r_np = np.array([reward_lookup[c] for c in range(1, C+1)], dtype=float)\n",
    "spec_list = sorted(mode_cat.unique().tolist())\n",
    "S = len(spec_list)\n",
    "spec_to_idx = {s:i for i,s in enumerate(spec_list)}\n",
    "data[\"SERVICE_CATEGORY_encoded\"] = data[\"SERVICE_CATEGORY\"].map(spec_to_idx)\n",
    "U_np = 420.0 * np.ones(S, dtype=float)\n",
    "B =  round(S * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b5db224-a825-4c39-bd63-4f36b825a793",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2023-03-01\")\n",
    "end_date   = pd.Timestamp(\"2024-03-01\")\n",
    "\n",
    "month_starts = []\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    month_starts.append(current)\n",
    "    current += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5944161-de70-4563-b1d7-f4cef78b2da4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scenario_cases   = {}\n",
    "scenario_counts  = {}\n",
    "\n",
    "for t0 in month_starts:\n",
    "    # 1) individuals waiting at t0 (handles NaT or SurgeryDate > t0)\n",
    "    cases_t0 = build_backlog_individual_at_t0(\n",
    "        data,\n",
    "        t0=t0,\n",
    "        group_cols=('surgeonID',),\n",
    "        reward_col='Reward_Group',\n",
    "        arrival_date_col='DecisiontoTreatDate',\n",
    "        treated_date_col='SurgeryDate',\n",
    "        cancel_col=None, cancel_values=None,\n",
    "        feature_cols=('Patient_Gender_Binary','DecisionYear','DecisionMonth','DecisionDay',\n",
    "                      'DecisionWeekday','PatientType_encoded','Case Mix Group_encoded', 'Case Mix Age Category_encoded',\n",
    "                     'Diagnosis1_encoded','ProcedureMnemonic_encoded','SERVICE_CATEGORY_encoded')\n",
    "    )\n",
    "    scenario_cases[t0] = cases_t0\n",
    "    counts_t0 = backlog_counts_at_t0(\n",
    "        cases_t0,\n",
    "        group_cols=('surgeonID',),\n",
    "        reward_col='Reward_Group',\n",
    "        n_rewards=15\n",
    "    )\n",
    "    scenario_counts[t0] = counts_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a01f3a-5910-4dae-83f2-6e68484e425d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spec_of_surgeon = np.array([spec_to_idx[mode_cat.loc[sid]] for sid in surgeons_list], dtype=int)\n",
    "surgeon_to_idx = {sid: i for i, sid in enumerate(surgeons_list)}\n",
    "N = len(surgeons_list)\n",
    "spec_of_surgeon_np = np.array(\n",
    "    [spec_to_idx.get(mode_cat.get(sid, np.nan), -1) for sid in surgeons_list],\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "G_sn_np = np.zeros((S, N), dtype=float)\n",
    "valid = spec_of_surgeon_np >= 0\n",
    "G_sn_np[spec_of_surgeon_np[valid], np.arange(N)[valid]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43de6a21-841c-45bc-bc77-2f9bb6b5f0d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "T = 8\n",
    "training_raw =  data[(data['DecisiontoTreatDate'] >= pd.Timestamp(\"2023-05-01\")) & (data['DecisiontoTreatDate'] <= pd.Timestamp(\"2024-03-01\"))].copy()\n",
    "scen_long, A_scenarios= build_arrival_scenarios_by_surgeon(\n",
    "    training_raw=training_raw, surgeons_list= surgeons_list,\n",
    "    n_scenarios=K, T=T, week_anchor=\"W-MON\", C=C, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad72885-057d-40ba-bc4f-c6a3567bb64c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NUM_COLS = ['DecisionYear','DecisionMonth','DecisionDay','DecisionWeekday']\n",
    "CAT_COLS = ['PatientType_encoded','Case Mix Group_encoded','Patient_Gender_Binary', \n",
    "            'Case Mix Age Category_encoded', 'Diagnosis1_encoded','SERVICE_CATEGORY_encoded']\n",
    "DATE_COLS = ['DecisiontoTreatDate', 'SurgeryDate']\n",
    "\n",
    "def fit_design_plain(df):\n",
    "    cat_levels  = {c: sorted(df[c].dropna().unique().tolist()) for c in CAT_COLS}\n",
    "\n",
    "    def transform(df_):\n",
    "        df_ = df_.copy()\n",
    "        df_.drop(columns=[c for c in DATE_COLS if c in df_.columns], errors='ignore', inplace=True)\n",
    "        dt_cols = df_.select_dtypes(include=['datetime64[ns]', 'datetimetz']).columns\n",
    "        if len(dt_cols):\n",
    "            df_.drop(columns=list(dt_cols), inplace=True)\n",
    "        for c in CAT_COLS:\n",
    "            df_[c] = pd.Categorical(df_[c], categories=cat_levels[c])\n",
    "\n",
    "        X_num  = df_[NUM_COLS].apply(pd.to_numeric, errors='coerce').astype('float64')\n",
    "        X_cat  = pd.get_dummies(df_[CAT_COLS], drop_first=True, dtype='float64')\n",
    "\n",
    "        X = pd.concat([pd.Series(1.0, index=df_.index, name='intercept', dtype='float64'),\n",
    "                       X_num, X_cat], axis=1)\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype('float64')\n",
    "        return X\n",
    "\n",
    "    X_fit = transform(df)\n",
    "    col_order = X_fit.columns.tolist()\n",
    "\n",
    "    def transform_fixed(df_):\n",
    "        return transform(df_).reindex(columns=col_order, fill_value=0.0).astype('float64')\n",
    "\n",
    "    return transform_fixed, col_order\n",
    "\n",
    "transform_fixed, design_cols = fit_design_plain(training_raw)  # or fit_design_no_spec_interactions\n",
    "dim = len(design_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b61b0b9d-ebef-4a0b-b4dc-94005928eef3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearSoftmaxMNL(nn.Module):\n",
    "    def __init__(self, d: int, C: int, *, bias: bool = False, init_std: float = 0.05, temperature: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.empty(C, d))\n",
    "        self.b = nn.Parameter(torch.zeros(C)) if bias else None\n",
    "        nn.init.normal_(self.W, std=init_std)   # small init to avoid peaky softmax\n",
    "        self.tau = float(temperature)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, return_logits: bool = False):\n",
    "        logits = X @ self.W.T\n",
    "        if self.b is not None:\n",
    "            logits = logits + self.b\n",
    "        if return_logits:\n",
    "            return logits\n",
    "        return F.softmax(logits / self.tau, dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def project_params(self):\n",
    "        pass  # keep for compatibility with your training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fdff6-6df3-4b59-a0d7-3a4cf569e52f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba27af8-ac7e-4a9c-934a-5cf5b478a1c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_first_stage_layer_SAA_arrivals(\n",
    "    N, S, C, T, Kb,\n",
    "    spec_of_surgeon_np, U_s_np, r_per_min_c_np, G_sn_np,\n",
    "    A_scenarios_np,               # <-- (Kb, N, C, T), fixed constants\n",
    "    beta_sc_np=None, rho=1e-3,\n",
    "    tau_nom_sc=None, Ymax=25, surgeon_cap=1800\n",
    "):\n",
    "    N=int(N); S=int(S); C=int(C); T=int(T); Kb=int(Kb)\n",
    "    spec = np.asarray(spec_of_surgeon_np, int).reshape(N)\n",
    "    U_s  = np.asarray(U_s_np, float).reshape(S)\n",
    "    r_c  = np.asarray(r_per_min_c_np, float).reshape(C)\n",
    "    G_sn = np.asarray(G_sn_np, float).reshape(S, N)\n",
    "    A_it = np.full((N, T), float(surgeon_cap), dtype=float)\n",
    "    if tau_nom_sc is None:\n",
    "        tau_sc = np.full((S, C), 100.0, dtype=float)\n",
    "        tau_sct = np.repeat(tau_sc[:, :, None], T, axis=2)\n",
    "    else:\n",
    "        arr = np.asarray(tau_nom_sc, float)\n",
    "        tau_sct = np.repeat(arr[:, :, None], T, axis=2) if arr.ndim==2 else arr\n",
    "    tau_ict  = tau_sct[spec, :, :]\n",
    "    rEff_ict = r_c[None, :, None] * tau_ict\n",
    "\n",
    "    BetaIc = None\n",
    "    if beta_sc_np is not None:\n",
    "        BetaIc = np.asarray(beta_sc_np, float).reshape(S, C)[spec, :]\n",
    "\n",
    "    # constants\n",
    "    UcS    = cp.Constant(U_s)\n",
    "    Gc     = cp.Constant(G_sn)\n",
    "    TauIcC = cp.Constant(tau_ict)\n",
    "    rEffC  = cp.Constant(rEff_ict)\n",
    "    AitC   = cp.Constant(A_it)\n",
    "    Aconst = cp.Constant(np.asarray(A_scenarios_np, float).reshape(Kb, N, C, T))\n",
    "    BetaIcC= (cp.Constant(BetaIc) if BetaIc is not None else None)\n",
    "\n",
    "    # parameter\n",
    "    p0 = cp.Parameter((N, C), nonneg=True)\n",
    "\n",
    "    # decisions\n",
    "    Y  = cp.Variable((S, T), nonneg=True)                 # shared\n",
    "    Xs = [cp.Variable((N, C, T), nonneg=True) for _ in range(Kb)]\n",
    "    Bs = [cp.Variable((N, C, T+1), nonneg=True) for _ in range(Kb)]\n",
    "\n",
    "    cons = []\n",
    "    if Ymax is not None:\n",
    "        for t in range(T):\n",
    "            cons += [cp.sum(Y[:, t]) <= float(Ymax)]     # only once, not per scenario\n",
    "\n",
    "    obj_terms = []\n",
    "    for k in range(Kb):\n",
    "        Xk, Bk = Xs[k], Bs[k]\n",
    "        cons += [Bk[:, :, 0] == p0]\n",
    "        for t in range(T):\n",
    "            cons += [Bk[:, :, t+1] == Bk[:, :, t] + Aconst[k, :, :, t] - Xk[:, :, t]]\n",
    "            minutes_i_t = cp.sum(cp.multiply(TauIcC[:, :, t], Xk[:, :, t]), axis=1)\n",
    "            cons += [minutes_i_t <= AitC[:, t]]\n",
    "            cons += [(Gc @ minutes_i_t) <= cp.multiply(UcS, Y[:, t])]\n",
    "\n",
    "        reward_k = cp.sum(cp.multiply(rEffC, Xk))\n",
    "        penalty_k = 0.0\n",
    "        penalty_k = cp.sum(cp.multiply(BetaIcC, cp.sum(cp.square(Bk[:, :, 1:]), axis=2)))\n",
    "        obj_terms.append(reward_k - penalty_k)\n",
    "        \n",
    "    regY = (rho/3.0) * cp.sum_squares(Y)\n",
    "    obj  = (1.0 / Kb) * cp.sum(obj_terms) - regY\n",
    "    prob = cp.Problem(cp.Maximize(obj), cons)\n",
    "    sm = prob.size_metrics\n",
    "    print(\"vars:\", sm.num_scalar_variables)\n",
    "    layer = CvxpyLayer(prob, parameters=[p0], variables=[Y])\n",
    "\n",
    "    def solve_layer(p0_torch):\n",
    "        outs = layer(p0_torch)\n",
    "        Y_t = outs[0]\n",
    "        X_list = outs[1:]\n",
    "        return Y_t, X_list\n",
    "\n",
    "    return solve_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3443292-ea3f-4997-a0d3-15879ada95ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars: 14870\n"
     ]
    }
   ],
   "source": [
    "beta_np = np.full((S, C), 0.01, dtype=float)  \n",
    "solve_first_stage = make_first_stage_layer_SAA_arrivals(\n",
    "    N, S, C, T, K,\n",
    "    spec_of_surgeon_np=spec_of_surgeon,\n",
    "    U_s_np=U_np, r_per_min_c_np=r_np,\n",
    "    G_sn_np=G_sn_np, A_scenarios_np= A_scenarios,\n",
    "    beta_sc_np=beta_np, tau_nom_sc=tau_nom_sc,\n",
    "    rho=1e-3, Ymax=25, surgeon_cap=1800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93867692-3a28-4c3b-ae9b-7423b8570d1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_second_stage_value_and_grad_SAA_arrivals(\n",
    "    N, S, C, T, Kb,\n",
    "    spec_of_surgeon_np,        # (N,) int -> specialty index in {0,...,S-1}\n",
    "    U_s_np,                    # (S,) minutes per unit of Y for each specialty\n",
    "    r_per_min_c_np,            # (C,) reward per minute\n",
    "    G_sn_np,                   # (S,N) indicator: G[s,i]=1 if surgeon i in specialty s\n",
    "    A_scenarios_np,            # (Kb, N, C, T) fixed arrival paths (constants)\n",
    "    beta_sc_np=None,           # (S,C) nonneg backlog penalty weights (or None)\n",
    "    tau_nom_sc=None,           # (S,C) or (S,C,T); default 100\n",
    "    surgeon_cap=1800,\n",
    "    penalty_norm=\"L2\",         # \"L1\" (linear, memory-light) or \"L2\" (quadratic)\n",
    "):\n",
    "\n",
    "    N=int(N); S=int(S); C=int(C); T=int(T); Kb=int(Kb)\n",
    "    spec = np.asarray(spec_of_surgeon_np, int).reshape(N)\n",
    "    U_s  = np.asarray(U_s_np,         float).reshape(S)\n",
    "    r_c  = np.asarray(r_per_min_c_np, float).reshape(C)\n",
    "    G_sn = np.asarray(G_sn_np,        float).reshape(S, N)\n",
    "    A_it = np.full((N, T), float(surgeon_cap), dtype=float)\n",
    "\n",
    "    # tau -> (S,C,T) then map to surgeons (N,C,T)\n",
    "    if tau_nom_sc is None:\n",
    "        tau_sc  = np.full((S, C), 100.0, float)\n",
    "        tau_sct = np.repeat(tau_sc[:, :, None], T, axis=2)\n",
    "    else:\n",
    "        arr = np.asarray(tau_nom_sc, float)\n",
    "        tau_sct = np.repeat(arr[:, :, None], T, axis=2) if arr.ndim==2 else arr\n",
    "    tau_ict  = tau_sct[spec, :, :]                  # (N,C,T)\n",
    "    r_eff_ict = r_c[None, :, None] * tau_ict        # (N,C,T)\n",
    "\n",
    "    BetaIc = None\n",
    "    if beta_sc_np is not None:\n",
    "        BetaIc = np.asarray(beta_sc_np, float).reshape(S, C)[spec, :]  # (N,C)\n",
    "\n",
    "    # Constants\n",
    "    UcS    = cp.Constant(U_s)\n",
    "    Gc     = cp.Constant(G_sn)\n",
    "    TauIcC = cp.Constant(tau_ict)\n",
    "    rEffC  = cp.Constant(r_eff_ict)\n",
    "    AitC   = cp.Constant(A_it)\n",
    "    Aconst = cp.Constant(np.asarray(A_scenarios_np, float).reshape(Kb, N, C, T))\n",
    "    BetaIcC= (cp.Constant(BetaIc) if BetaIc is not None else None)\n",
    "\n",
    "    # Parameters (inputs to the recourse)\n",
    "    Yp = cp.Parameter((S, T), nonneg=True)      # first-stage blocks (shared across scenarios)\n",
    "    p0 = cp.Parameter((N, C), nonneg=True)      # initial backlog\n",
    "\n",
    "    # Decisions per scenario\n",
    "    Xs = [cp.Variable((N, C, T),  nonneg=True) for _ in range(Kb)]\n",
    "    Bs = [cp.Variable((N, C, T+1), nonneg=True) for _ in range(Kb)]\n",
    "\n",
    "    cons = []\n",
    "    # Track the specialty-capacity constraints per scenario/week to read duals later\n",
    "    cap_cons = [[None for _ in range(T)] for _ in range(Kb)]\n",
    "\n",
    "    for k in range(Kb):\n",
    "        Xk, Bk = Xs[k], Bs[k]\n",
    "        cons += [Bk[:, :, 0] == p0]\n",
    "        for t in range(T):\n",
    "            cons += [Bk[:, :, t+1] == Bk[:, :, t] + Aconst[k, :, :, t] - Xk[:, :, t]]\n",
    "            minutes_i_t = cp.sum(cp.multiply(TauIcC[:, :, t], Xk[:, :, t]), axis=1)  # (N,)\n",
    "            cons += [minutes_i_t <= AitC[:, t]]\n",
    "\n",
    "            # Specialty capacity tied to Yp (non-anticipative)\n",
    "            cap = (Gc @ minutes_i_t) <= cp.multiply(UcS, Yp[:, t])                  # (S,)\n",
    "            cons.append(cap)\n",
    "            cap_cons[k][t] = cap\n",
    "\n",
    "    obj_terms = []\n",
    "    for k in range(Kb):\n",
    "        Xk, Bk = Xs[k], Bs[k]\n",
    "        reward_k = cp.sum(cp.multiply(rEffC, Xk))\n",
    "        if BetaIcC is None:\n",
    "            pen_k = 0.0\n",
    "        else:\n",
    "            if penalty_norm.upper() == \"L2\":\n",
    "                # quadratic per (i,c) on entire trajectory (QP; may be heavier)\n",
    "                pen_k = cp.sum(cp.multiply(BetaIcC, cp.sum(cp.square(Bk[:, :, 1:]), axis=2)))\n",
    "            else:\n",
    "                # default: linear (memory-friendly)\n",
    "                pen_k = cp.sum(cp.multiply(BetaIcC, cp.sum(Bk[:, :, 1:], axis=2)))\n",
    "        obj_terms.append(reward_k - pen_k)\n",
    "\n",
    "    obj = cp.Maximize((1.0 / Kb) * cp.sum(obj_terms))  # sample average\n",
    "    prob = cp.Problem(obj, cons)\n",
    "\n",
    "    def solve(Y_val, p0_val, *, solver=cp.GUROBI, **solver_opts):\n",
    "        Yp.value = np.maximum(np.asarray(Y_val,  float).reshape(S, T), 0.0)\n",
    "        p0.value = np.maximum(np.asarray(p0_val, float).reshape(N, C), 0.0)\n",
    "        prob.solve(solver=solver, **solver_opts)\n",
    "        if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "            raise RuntimeError(f\"Second-stage not optimal: {prob.status}\")\n",
    "\n",
    "        v_avg = float(prob.value)  # already averaged by (1/Kb)\n",
    "        Pi_avg = np.zeros((S, T), dtype=float)\n",
    "        for t in range(T):\n",
    "            acc = np.zeros(S, dtype=float)\n",
    "            for k in range(Kb):\n",
    "                acc += cap_cons[k][t].dual_value\n",
    "            Pi_avg[:, t] = acc\n",
    "        gradY = U_s[:, None] * Pi_avg\n",
    "\n",
    "        return v_avg, gradY\n",
    "\n",
    "    return solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35192700-a814-4fe1-b867-fd4cc6aad43e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assumes you've already defined: S, C, T, U_np, r_per_min_c_np (shape (C,)), beta_np, tau_nom_np\n",
    "second_stage = make_second_stage_value_and_grad_SAA_arrivals(\n",
    "    N=N, S=S, C=C, T=T, Kb=K,\n",
    "    spec_of_surgeon_np = spec_of_surgeon_np,\n",
    "    U_s_np=U_np,\n",
    "    r_per_min_c_np=r_np, \n",
    "    G_sn_np = G_sn_np,\n",
    "    A_scenarios_np= A_scenarios,\n",
    "    beta_sc_np=beta_np,\n",
    "    tau_nom_sc=tau_nom_sc,\n",
    "    penalty_norm=\"L2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "565f31b4-0adb-48f8-a09f-349a4198bc4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def to_surgeon_idx(series):\n",
    "    \"\"\"Map a pandas Series of surgeonIDs -> integer indices (may contain NaN).\"\"\"\n",
    "    return series.map(surgeon_to_idx)\n",
    "    \n",
    "def build_p_and_d_for_t0_by_surgeon(\n",
    "    cases_t0: pd.DataFrame,\n",
    "    counts_t0: pd.DataFrame,\n",
    "    model,\n",
    "    transform_fixed,\n",
    "    C: int,\n",
    "    mode_cat: pd.Series | None = None,   # Series: index=surgeonID, value=SERVICE_CATEGORY\n",
    "    ensure_service_category: bool = True\n",
    "):\n",
    "\n",
    "    if ensure_service_category and 'SERVICE_CATEGORY' not in cases_t0.columns:\n",
    "        cases_t0 = cases_t0.merge(\n",
    "            mode_cat.rename('SERVICE_CATEGORY'),\n",
    "            left_on='surgeonID', right_index=True, how='left'\n",
    "        )\n",
    "\n",
    "    # --- 1) Predict per case, then aggregate to surgeon\n",
    "    X_df = transform_fixed(cases_t0)\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "    X = torch.as_tensor(X_df.to_numpy(), dtype=torch_dtype, device=device)\n",
    "    P_cases = model(X)  # (n_cases, C)\n",
    "\n",
    "    idx_series = to_surgeon_idx(cases_t0['surgeonID'])\n",
    "    mask = idx_series.notna().to_numpy()\n",
    "    idx_torch = torch.as_tensor(idx_series[mask].to_numpy(dtype=int), dtype=torch.long, device=device)\n",
    "    P_cases_sel = P_cases[torch.as_tensor(mask, device=device)]\n",
    "    p = torch.zeros((N, C), dtype=P_cases.dtype, device=device)\n",
    "    p.index_add_(0, idx_torch, P_cases_sel)\n",
    "\n",
    "    # --- 2) True counts per surgeon\n",
    "    cols = [f'y_r{c}' for c in range(1, C+1)]\n",
    "    for col in cols:\n",
    "        if col not in counts_t0.columns:\n",
    "            counts_t0[col] = 0\n",
    "\n",
    "    d_by_surgeon = (counts_t0\n",
    "                    .groupby('surgeonID', dropna=False)[cols]\n",
    "                    .sum())\n",
    "\n",
    "    # align to surgeons_list order\n",
    "    d_by_surgeon = d_by_surgeon.reindex(surgeons_list, fill_value=0)\n",
    "    d_true = d_by_surgeon.to_numpy(dtype=float)  # (N, C)\n",
    "\n",
    "    return p, d_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85e270e5-cb4f-4279-971e-5f9a957b2a52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = LinearSoftmaxMNL(dim, C)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eb14e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cvxpy_param(x: torch.Tensor) -> torch.Tensor:\n",
    "    # cvxpylayers wants CPU + torch.double; keep the graph intact\n",
    "    if x.device.type != \"cpu\":\n",
    "        x = x.cpu()\n",
    "    if x.dtype != torch.double:\n",
    "        x = x.double()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "007c6a8e-1e13-4761-8c35-27df9dae3fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2721691\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "epoch 1: sum P = 938.7150\n",
      "epoch 2: sum P = 938.7101\n",
      "epoch 3: sum P = 936.8318\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.20 GiB for an array with shape (967026609,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m loss_batch = loss_batch / \u001b[38;5;28mlen\u001b[39m(batch_t0s)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# backprop once for the batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mloss_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m GRAD_CLIP \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\torch\\autograd\\function.py:311\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mImplementing both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvjp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for a custom \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFunction is not allowed. You should only implement one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m     )\n\u001b[32m    310\u001b[39m user_fn = vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function.vjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\cvxpylayers\\torch\\cvxpylayer.py:317\u001b[39m, in \u001b[36m_CvxpyLayerFn.<locals>._CvxpyLayerFnFn.backward\u001b[39m\u001b[34m(ctx, *dvars)\u001b[39m\n\u001b[32m    300\u001b[39m dvars_numpy = [to_numpy(dvar) \u001b[38;5;28;01mfor\u001b[39;00m dvar \u001b[38;5;129;01min\u001b[39;00m dvars]\n\u001b[32m    302\u001b[39m context = BackwardContext(\n\u001b[32m    303\u001b[39m     info=info,\n\u001b[32m    304\u001b[39m     gp=gp,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     sol=info[\u001b[33m'\u001b[39m\u001b[33msol\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m gp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    315\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m grad_numpy, info_backward = \u001b[43m_backward_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvars_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# convert to torch tensors and incorporate info_backward\u001b[39;00m\n\u001b[32m    320\u001b[39m grad = [to_torch(g, ctx.dtype, ctx.device) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_numpy]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\cvxpylayers\\utils.py:144\u001b[39m, in \u001b[36mbackward_numpy\u001b[39m\u001b[34m(dvars_numpy, context)\u001b[39m\n\u001b[32m    142\u001b[39m grad = [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(context.param_ids))]\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(context.batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     del_param_dict = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_param_jac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mdAs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j, pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(context.param_ids):\n\u001b[32m    147\u001b[39m         grad[j].append(np.expand_dims(del_param_dict[pid], \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\cvxpy\\reductions\\dcp2cone\\cone_matrix_stuffing.py:253\u001b[39m, in \u001b[36mParamConeProg.apply_param_jac\u001b[39m\u001b[34m(self, delc, delA, delb, active_params)\u001b[39m\n\u001b[32m    248\u001b[39m     del_param_vec += np.squeeze(\u001b[38;5;28mself\u001b[39m.A.T.dot(delAb.toarray()))\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# slow path.\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;66;03m# TODO: make this faster by intelligently operating on the\u001b[39;00m\n\u001b[32m    252\u001b[39m     \u001b[38;5;66;03m# sparse matrix data / making use of reduced_A\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     del_param_vec += np.squeeze((\u001b[43mdelAb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mA\u001b[49m).toarray())\n\u001b[32m    254\u001b[39m del_param_vec = np.squeeze(del_param_vec)\n\u001b[32m    256\u001b[39m param_id_to_delta_param = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_base.py:908\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    907\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_coo.py:695\u001b[39m, in \u001b[36m_coo_base._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    692\u001b[39m         other = other_a\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim < \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other.ndim < \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_spbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m N = \u001b[38;5;28mself\u001b[39m.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m    698\u001b[39m err_prefix = \u001b[33m\"\u001b[39m\u001b[33mmatmul: dimension mismatch with signature\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_base.py:812\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m N != other.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m    809\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    810\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (n,k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m),(k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,m)->(n,m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    811\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[32m    815\u001b[39m other_a = np.asanyarray(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_coo.py:1106\u001b[39m, in \u001b[36m_coo_base._matmul_sparse\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1093\u001b[39m \u001b[33;03mPerform sparse-sparse matrix multiplication for two n-D COO arrays.\u001b[39;00m\n\u001b[32m   1094\u001b[39m \u001b[33;03mThe method converts input n-D arrays to 2-D block array format,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1103\u001b[39m \u001b[33;03mprod (COO): The resulting n-D sparse array after multiplication.\u001b[39;00m\n\u001b[32m   1104\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim < \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other.ndim < \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_spbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[38;5;66;03m# Get the shapes of self and other\u001b[39;00m\n\u001b[32m   1109\u001b[39m self_shape = \u001b[38;5;28mself\u001b[39m.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_base.py:884\u001b[39m, in \u001b[36m_spbase._matmul_sparse\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_matmul_sparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtocsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:432\u001b[39m, in \u001b[36m_cs_matrix._matmul_sparse\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    429\u001b[39m     new_shape += (N,)\n\u001b[32m    430\u001b[39m faux_shape = (M \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m, N \u001b[38;5;28;01mif\u001b[39;00m o_ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m other = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# convert to this format\u001b[39;00m\n\u001b[32m    433\u001b[39m index_arrays = (\u001b[38;5;28mself\u001b[39m.indptr, \u001b[38;5;28mself\u001b[39m.indices, other.indptr, other.indices)\n\u001b[32m    435\u001b[39m M, N = \u001b[38;5;28mself\u001b[39m._swap((M, N))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:37\u001b[39m, in \u001b[36m_cs_matrix.__init__\u001b[39m\u001b[34m(self, arg1, shape, dtype, copy, maxprint)\u001b[39m\n\u001b[32m     35\u001b[39m         arg1 = arg1.copy()\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         arg1 = \u001b[43marg1\u001b[49m\u001b[43m.\u001b[49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m.indptr, \u001b[38;5;28mself\u001b[39m.indices, \u001b[38;5;28mself\u001b[39m.data, \u001b[38;5;28mself\u001b[39m._shape = (\n\u001b[32m     39\u001b[39m         arg1.indptr, arg1.indices, arg1.data, arg1._shape\n\u001b[32m     40\u001b[39m     )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg1, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_base.py:480\u001b[39m, in \u001b[36m_spbase.asformat\u001b[39m\u001b[34m(self, format, copy)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_coo.py:373\u001b[39m, in \u001b[36m_coo_base.tocsr\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_array\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     arrays = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coo_to_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsr_array\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_swap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     indptr, indices, data, shape = arrays\n\u001b[32m    376\u001b[39m     x = \u001b[38;5;28mself\u001b[39m._csr_container((data, indices, indptr), shape=\u001b[38;5;28mself\u001b[39m.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chunr\\CMH_project\\Lib\\site-packages\\scipy\\sparse\\_coo.py:401\u001b[39m, in \u001b[36m_coo_base._coo_to_compressed\u001b[39m\u001b[34m(self, swap, copy)\u001b[39m\n\u001b[32m    398\u001b[39m major = major.astype(idx_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    399\u001b[39m minor = minor.astype(idx_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m indptr = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m indices = np.empty_like(minor, dtype=idx_dtype)\n\u001b[32m    403\u001b[39m data = np.empty_like(\u001b[38;5;28mself\u001b[39m.data, dtype=\u001b[38;5;28mself\u001b[39m.dtype)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 7.20 GiB for an array with shape (967026609,) and data type int64"
     ]
    }
   ],
   "source": [
    "EPOCHS      = 8\n",
    "BATCH_SIZE  = 4\n",
    "GRAD_CLIP   = 100\n",
    "month_starts_list = list(month_starts)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    random.shuffle(month_starts_list)\n",
    "    epoch_total_val = 0.0\n",
    "\n",
    "    for b in range(0, len(month_starts_list), BATCH_SIZE):\n",
    "        batch_t0s = month_starts_list[b:b+BATCH_SIZE]\n",
    "        opt.zero_grad()\n",
    "        loss_batch = 0.0\n",
    "        val_batch  = 0.0\n",
    "\n",
    "        for t0 in batch_t0s:\n",
    "            cases_t0  = scenario_cases[t0]\n",
    "            counts_t0 = scenario_counts[t0]\n",
    "            p_t, d_true_np = build_p_and_d_for_t0_by_surgeon(\n",
    "                cases_t0, counts_t0, model, transform_fixed, C, mode_cat=mode_cat\n",
    "            )\n",
    "            # p_t requires grad through model  keep graph; just cast for cvxpylayers:\n",
    "            p_t_cvx = to_cvxpy_param(p_t)\n",
    "\n",
    "            # --- 2) First stage (unchanged unpack; you keep the extra return) ---\n",
    "            Y_star_t, _ = solve_first_stage(p_t_cvx)     # Y_star_t: CPU, double\n",
    "\n",
    "            # --- 3) Second stage (numpy in/out) ---\n",
    "            Y_star_np = Y_star_t.detach().cpu().numpy()\n",
    "            v, gradY_np = second_stage(\n",
    "                Y_val=Y_star_np,\n",
    "                p0_val=d_true_np,\n",
    "                solver=cp.GUROBI,\n",
    "                verbose=False,\n",
    "            )\n",
    "            val_batch += float(v)\n",
    "\n",
    "            # --- 4) Decision-focused loss: Y, (obj)/Y = Y, gradY ---\n",
    "            gY = torch.as_tensor(gradY_np, dtype=Y_star_t.dtype, device=Y_star_t.device)  # (S,T)\n",
    "            loss_batch = loss_batch + (Y_star_t * gY).sum()\n",
    "\n",
    "        # average over this mini-batch (optional)\n",
    "        loss_batch = loss_batch / len(batch_t0s)\n",
    "\n",
    "        # backprop once for the batch\n",
    "        loss_batch.backward()\n",
    "        if GRAD_CLIP is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        opt.step()\n",
    "\n",
    "        # your new NN has a no-op project_params(); keep the call to avoid touching other code\n",
    "        with torch.no_grad():\n",
    "            model.project_params()\n",
    "\n",
    "        epoch_total_val += val_batch\n",
    "\n",
    "    print(f\"epoch {epoch+1}: sum P = {epoch_total_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546018e6-3540-42f8-8ede-cbe8d4b0e8eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02d13f99-e843-4c07-9d1a-0d402981a37b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repo_root = Path.cwd()\n",
    "save_dir = repo_root / \"models\" / \"LinearSoftmaxMNL\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# minimal config to rebuild the module\n",
    "model_cfg = {\n",
    "    \"d_dim\": int(d_dim),\n",
    "    \"C\": int(C),\n",
    "    \"ref_class\": int(C-1),\n",
    "    \"design_cols\": list(design_cols),\n",
    "    \"clamp\": {\"alpha\":16.0,\"beta\":14.0,\"gamma\":10.0,\"delta\":14.0},\n",
    "}\n",
    "\n",
    "torch.save(model.state_dict(), save_dir / \"weights.pt\")\n",
    "with open(save_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(model_cfg, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bce5df2-36ea-4968-98f1-f883e8b7e638",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def solve_with_SAA(\n",
    "    N, S, C, T, Kb,\n",
    "    spec_of_surgeon_np, U_s_np, r_per_min_c_np, G_sn_np,\n",
    "    A_scenarios_np,               # shape (Kb, N, C, T)\n",
    "    p0_np,                        # shape (N, C): initial backlog (d^0); nonnegative\n",
    "    beta_sc_np=None,              # optional shape (S, C) for backlog penalty weights\n",
    "    rho=1e-3,\n",
    "    tau_nom_sc=None,              # (S, C) or (S, C, T); per-case minutes\n",
    "    Ymax=25,\n",
    "    surgeon_cap=1800,\n",
    "    solver=\"GUROBI\",\n",
    "    verbose=False,\n",
    "    **solve_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Y_val      : (S, T) optimal first-stage blocks\n",
    "        X_vals     : list length Kb, each (N, C, T) case selections\n",
    "        B_vals     : list length Kb, each (N, C, T+1) backlogs\n",
    "        obj_value  : optimal objective value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Cast & basic tensors ----\n",
    "    N=int(N); S=int(S); C=int(C); T=int(T); Kb=int(Kb)\n",
    "\n",
    "    spec = np.asarray(spec_of_surgeon_np, int).reshape(N)        # surgeon -> specialty index in [0, S)\n",
    "    U_s  = np.asarray(U_s_np, float).reshape(S)                   # surgeon-minute capacity per specialty\n",
    "    r_c  = np.asarray(r_per_min_c_np, float).reshape(C)           # reward per OR minute for class c\n",
    "    G_sn = np.asarray(G_sn_np, float).reshape(S, N)               # S x N mapping minutes to specialties\n",
    "    A_it = np.full((N, T), float(surgeon_cap), dtype=float)       # per-surgeon per-period minute cap\n",
    "    A_scen = np.asarray(A_scenarios_np, float).reshape(Kb, N, C, T)\n",
    "    p0_np = np.asarray(p0_np, float).reshape(N, C)\n",
    "\n",
    "    # tau_nom_sc: (S,C) or (S,C,T) -> build (S,C,T)\n",
    "    if tau_nom_sc is None:\n",
    "        tau_sc = np.full((S, C), 100.0, dtype=float)\n",
    "        tau_sct = np.repeat(tau_sc[:, :, None], T, axis=2)       # (S, C, T)\n",
    "    else:\n",
    "        arr = np.asarray(tau_nom_sc, float)\n",
    "        if arr.ndim == 2:                                        # (S, C)\n",
    "            tau_sct = np.repeat(arr[:, :, None], T, axis=2)\n",
    "        elif arr.ndim == 3:                                      # (S, C, T)\n",
    "            tau_sct = arr\n",
    "        else:\n",
    "            raise ValueError(\"tau_nom_sc must be (S,C) or (S,C,T).\")\n",
    "\n",
    "    # Map to surgeon-level (N,C,T)\n",
    "    tau_ict  = tau_sct[spec, :, :]                               # (N, C, T)\n",
    "    rEff_ict = r_c[None, :, None] * tau_ict                      # (N, C, T), reward per case = r_c * minutes\n",
    "\n",
    "    # Optional backlog penalty weights Beta (N,C) from (S,C)\n",
    "    BetaIc = None\n",
    "    if beta_sc_np is not None:\n",
    "        BetaIc = np.asarray(beta_sc_np, float).reshape(S, C)[spec, :]  # (N, C)\n",
    "\n",
    "    # ---- Constants ----\n",
    "    UcS     = cp.Constant(U_s)              # (S,)\n",
    "    Gc      = cp.Constant(G_sn)             # (S, N)\n",
    "    TauIcC  = cp.Constant(tau_ict)          # (N, C, T)\n",
    "    rEffC   = cp.Constant(rEff_ict)         # (N, C, T)\n",
    "    AitC    = cp.Constant(A_it)             # (N, T)\n",
    "    Aconst  = cp.Constant(A_scen)           # (Kb, N, C, T)\n",
    "    BetaIcC = (cp.Constant(BetaIc) if BetaIc is not None else None)\n",
    "\n",
    "    # ---- Decision variables ----\n",
    "    Y  = cp.Variable((S, T), nonneg=True)                    # shared across scenarios\n",
    "    Xs = [cp.Variable((N, C, T), nonneg=True) for _ in range(Kb)]\n",
    "    Bs = [cp.Variable((N, C, T+1), nonneg=True) for _ in range(Kb)]\n",
    "\n",
    "    # ---- Constraints ----\n",
    "    cons = []\n",
    "\n",
    "    # Block-limit per period\n",
    "    if Ymax is not None:\n",
    "        for t in range(T):\n",
    "            cons.append(cp.sum(Y[:, t]) <= float(Ymax))\n",
    "\n",
    "    # Per-scenario flow & capacities\n",
    "    for k in range(Kb):\n",
    "        Xk, Bk = Xs[k], Bs[k]\n",
    "\n",
    "        # Backlog flow: B_{t+1} = B_t + arrivals - service, with B_0 = p0\n",
    "        cons.append(Bk[:, :, 0] == p0_np)\n",
    "        for t in range(T):\n",
    "            cons.append(Bk[:, :, t+1] == Bk[:, :, t] + Aconst[k, :, :, t] - Xk[:, :, t])\n",
    "\n",
    "            # Surgeon minutes this period\n",
    "            minutes_i_t = cp.sum(cp.multiply(TauIcC[:, :, t], Xk[:, :, t]), axis=1)  # (N,)\n",
    "            cons.append(minutes_i_t <= AitC[:, t])                                   # per-surgeon cap\n",
    "            cons.append((Gc @ minutes_i_t) <= cp.multiply(UcS, Y[:, t]))\n",
    "\n",
    "    # ---- Objective ----\n",
    "    scenario_terms = []\n",
    "    for k in range(Kb):\n",
    "        Xk, Bk = Xs[k], Bs[k]\n",
    "        reward_k  = cp.sum(cp.multiply(rEffC, Xk))  # sum over (i,c,t)\n",
    "        if BetaIcC is not None:\n",
    "            # To weight per (i,c), expand Beta and sum manually:\n",
    "            penalty_k = cp.sum(cp.multiply(BetaIcC, cp.sum(cp.square(Bk[:, :, 1:]), axis=2)))\n",
    "        else:\n",
    "            penalty_k = 0.0\n",
    "        scenario_terms.append(reward_k - penalty_k)\n",
    "\n",
    "    regY = (rho / 3.0) * cp.sum_squares(Y)\n",
    "    obj  = (1.0 / Kb) * cp.sum(scenario_terms) - regY\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(obj), cons)\n",
    "\n",
    "    prob.solve(solver=solver, verbose=verbose, **solve_kwargs)\n",
    "    Y_val  = Y.value\n",
    "    X_vals = [X.value for X in Xs]\n",
    "    B_vals = [B.value for B in Bs]\n",
    "    return Y_val, X_vals, B_vals, prob.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35b1d2-0ba6-488a-ad1e-61241c1b27a5",
   "metadata": {},
   "source": [
    "#### Genertae Y* for out of sample validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23a72714-a5b2-4b85-9841-6399b4d5ece3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# just try to rebuild the SAA sampples\n",
    "K = 5\n",
    "T = 8\n",
    "training_raw =  data[(data['DecisiontoTreatDate'] >= pd.Timestamp(\"2023-05-01\")) & (data['DecisiontoTreatDate'] <= pd.Timestamp(\"2024-03-01\"))].copy()\n",
    "scen_long, A_scenarios= build_arrival_scenarios_by_surgeon(\n",
    "    training_raw=training_raw, surgeons_list=surgeons_list,\n",
    "    n_scenarios=K, T=T, week_anchor=\"W-MON\", C=C, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe747f1-223f-44ba-945a-68b3a513537b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2024-03-01\")\n",
    "end_date   = pd.Timestamp(\"2024-08-01\")\n",
    "\n",
    "month_starts_test = []\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    month_starts_test.append(current)\n",
    "    current += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "773c803c-1f8d-4490-88b8-91f31d66cf25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2024-03-01 00:00:00'),\n",
       " Timestamp('2024-04-01 00:00:00'),\n",
       " Timestamp('2024-05-01 00:00:00'),\n",
       " Timestamp('2024-06-01 00:00:00'),\n",
       " Timestamp('2024-07-01 00:00:00'),\n",
       " Timestamp('2024-08-01 00:00:00')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_starts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "152105ee-a659-4723-8f0b-4c6587a90d94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scenario_cases_test   = {}\n",
    "scenario_counts_test  = {}\n",
    "scenario_queues_test  = {}\n",
    "\n",
    "for t0 in month_starts_test:\n",
    "    # 1) individuals waiting at t0 (handles NaT or SurgeryDate > t0)\n",
    "    cases_t0 = build_backlog_individual_at_t0(\n",
    "        data,\n",
    "        t0=t0,\n",
    "        group_cols=('surgeonID',),                 # add 'SERVICE_CATEGORY' here if you want (surgeon, specialty)\n",
    "        reward_col='Reward_Group',\n",
    "        arrival_date_col='DecisiontoTreatDate',\n",
    "        treated_date_col='SurgeryDate',\n",
    "        cancel_col=None, cancel_values=None,\n",
    "        feature_cols=('Patient_Gender_Binary','DecisionYear','DecisionMonth','DecisionDay',\n",
    "                      'DecisionWeekday','PatientType_encoded','Case Mix Group_encoded', 'Case Mix Age Category_encoded',\n",
    "                     'Diagnosis1_encoded','ProcedureMnemonic_encoded', 'SERVICE_CATEGORY_encoded')\n",
    "    )\n",
    "    scenario_cases_test[t0] = cases_t0\n",
    "    \n",
    "    counts_t0 = backlog_counts_at_t0(\n",
    "        cases_t0,\n",
    "        group_cols=('surgeonID',),\n",
    "        reward_col='Reward_Group',\n",
    "        n_rewards=15\n",
    "    )\n",
    "    scenario_counts_test[t0] = counts_t0\n",
    "    scenario_queues_test[t0] = counts_df_to_dict(counts_t0, group_col='surgeonID', n_rewards=15, keep_zeros=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "844fb4c0-d49d-4a6c-b16e-22b0b2afd733",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:37 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:37 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:37 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:37 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:37 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:37 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Nov 03 11:43:37 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:37 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:37 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:37 AM: Applying reduction Qp2SymbolicQp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:41 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Nov 03 11:43:41 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:41 AM: Finished problem compilation (took 4.114e+00 seconds).\n",
      "(CVXPY) Nov 03 11:43:41 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0x2d2d2686\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e-12, 2e+03]\n",
      "Presolve removed 30869 rows and 40028 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 7674 rows, 14427 columns, 33600 nonzeros\n",
      "Presolved model has 7866 quadratic objective terms\n",
      "Ordering time: 0.01s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.064e+04\n",
      " Factor NZ  : 1.131e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.833e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.94145101e+08 -4.03536045e+08  1.10e+04 1.00e+03  9.98e+05     0s\n",
      "   1   1.54399173e+08 -1.59923082e+08  4.48e+03 4.07e+02  5.18e+05     0s\n",
      "   2   1.76452949e+07 -2.11505223e+07  8.41e+02 7.65e+01  1.13e+05     0s\n",
      "   3  -1.93682885e+02 -3.06886301e+06  2.76e+01 2.51e+00  4.28e+03     0s\n",
      "   4  -1.10593487e+03 -1.68298561e+06  2.26e+00 2.05e-01  4.95e+02     0s\n",
      "   5  -1.47237176e+02 -9.82623571e+05  7.90e-01 7.18e-02  2.10e+02     0s\n",
      "   6   4.73458288e+02 -5.18605600e+05  2.53e-01 2.30e-02  8.69e+01     0s\n",
      "   7   9.65386301e+02 -1.32274021e+05  3.29e-02 2.99e-03  1.81e+01     0s\n",
      "   8   6.10814840e+02 -4.66805479e+04  1.02e-02 9.24e-04  6.21e+00     0s\n",
      "   9  -2.12172996e+02 -1.40488464e+04  6.47e-04 5.88e-05  1.76e+00     0s\n",
      "  10  -8.25976219e+02 -3.87813575e+03  6.75e-05 6.14e-06  3.86e-01     0s\n",
      "  11  -1.01674085e+03 -2.86660759e+03  3.25e-05 2.95e-06  2.35e-01     0s\n",
      "  12  -1.13688932e+03 -2.15770917e+03  1.35e-05 1.23e-06  1.30e-01     0s\n",
      "  13  -1.20303521e+03 -1.91232531e+03  8.11e-06 7.37e-07  9.04e-02     0s\n",
      "  14  -1.24171313e+03 -1.77014178e+03  5.21e-06 4.74e-07  6.75e-02     0s\n",
      "  15  -1.25397830e+03 -1.71680844e+03  4.20e-06 3.82e-07  5.92e-02     0s\n",
      "  16  -1.27948632e+03 -1.61888771e+03  2.65e-06 2.41e-07  4.35e-02     0s\n",
      "  17  -1.29535705e+03 -1.57933828e+03  1.71e-06 1.56e-07  3.65e-02     0s\n",
      "  18  -1.30647599e+03 -1.54430288e+03  1.26e-06 1.15e-07  3.06e-02     0s\n",
      "  19  -1.33883354e+03 -1.44066062e+03  2.48e-07 2.26e-08  1.30e-02     0s\n",
      "  20  -1.35636840e+03 -1.40726762e+03  7.38e-08 6.82e-09  6.49e-03     0s\n",
      "  21  -1.36688148e+03 -1.38821031e+03  1.24e-08 1.30e-09  2.71e-03     0s\n",
      "  22  -1.37204435e+03 -1.37994410e+03  7.35e-10 4.97e-10  9.96e-04     0s\n",
      "  23  -1.37445688e+03 -1.37680239e+03  1.31e-10 1.40e-09  2.96e-04     0s\n",
      "  24  -1.37540957e+03 -1.37573772e+03  9.67e-12 9.38e-10  4.13e-05     0s\n",
      "  25  -1.37552371e+03 -1.37554695e+03  4.75e-13 1.40e-09  2.92e-06     0s\n",
      "  26  -1.37553098e+03 -1.37553403e+03  1.46e-12 5.53e-10  3.84e-07     0s\n",
      "  27  -1.37553184e+03 -1.37553236e+03  4.49e-12 7.66e-11  6.64e-08     0s\n",
      "  28  -1.37553202e+03 -1.37553206e+03  2.23e-12 2.23e-11  4.65e-09     0s\n",
      "  29  -1.37553203e+03 -1.37553204e+03  8.52e-12 1.09e-11  4.70e-10     0s\n",
      "\n",
      "Barrier solved model in 29 iterations and 0.19 seconds (0.17 work units)\n",
      "Optimal objective -1.37553203e+03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:42 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:42 AM: Optimal value: 1.376e+03\n",
      "(CVXPY) Nov 03 11:43:42 AM: Compilation took 4.114e+00 seconds\n",
      "(CVXPY) Nov 03 11:43:42 AM: Solver (including time spent in interface) took 3.759e-01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:42 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:42 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:42 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:42 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:42 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:42 AM: Compiling problem (target solver=GUROBI).\n",
      "(CVXPY) Nov 03 11:43:42 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:42 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:42 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:42 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Nov 03 11:43:42 AM: Applying reduction QpMatrixStuffing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:42 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:42 AM: Finished problem compilation (took 3.256e-01 seconds).\n",
      "(CVXPY) Nov 03 11:43:42 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0xaa2d4909\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-11, 2e+03]\n",
      "Presolve removed 30885 rows and 40067 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 7658 rows, 14388 columns, 33530 nonzeros\n",
      "Presolved model has 7846 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.061e+04\n",
      " Factor NZ  : 1.116e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.791e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.93185037e+08 -4.02505030e+08  1.10e+04 1.00e+03  9.98e+05     0s\n",
      "   1   1.53587284e+08 -1.59054251e+08  4.47e+03 4.06e+02  5.17e+05     0s\n",
      "   2   1.77576162e+07 -2.12097634e+07  8.39e+02 7.63e+01  1.13e+05     0s\n",
      "   3   7.37653056e+01 -3.01674959e+06  2.74e+01 2.49e+00  4.23e+03     0s\n",
      "   4  -1.35673286e+03 -1.67945147e+06  2.22e+00 2.02e-01  4.89e+02     0s\n",
      "   5  -4.00249605e+02 -9.36650456e+05  7.34e-01 6.67e-02  1.96e+02     0s\n",
      "   6   2.83857966e+02 -5.18283480e+05  2.36e-01 2.15e-02  8.61e+01     0s\n",
      "   7   7.33900062e+02 -1.21861356e+05  2.47e-02 2.25e-03  1.64e+01     0s\n",
      "   8   4.03784881e+02 -3.84897068e+04  7.11e-03 6.46e-04  5.08e+00     0s\n",
      "   9  -3.22258096e+02 -9.20101878e+03  3.49e-04 3.18e-05  1.13e+00     0s\n",
      "  10  -8.94130945e+02 -3.80018304e+03  7.61e-05 6.92e-06  3.69e-01     0s\n",
      "  11  -1.08428701e+03 -2.95199848e+03  3.59e-05 3.26e-06  2.38e-01     0s\n",
      "  12  -1.20165804e+03 -2.26274775e+03  1.57e-05 1.42e-06  1.35e-01     0s\n",
      "  13  -1.27225876e+03 -2.00399253e+03  9.24e-06 8.40e-07  9.35e-02     0s\n",
      "  14  -1.31203387e+03 -1.86178555e+03  5.86e-06 5.33e-07  7.04e-02     0s\n",
      "  15  -1.31669600e+03 -1.84150038e+03  5.43e-06 4.94e-07  6.72e-02     0s\n",
      "  16  -1.35013105e+03 -1.70929174e+03  3.10e-06 2.82e-07  4.61e-02     0s\n",
      "  17  -1.36217953e+03 -1.66228487e+03  2.58e-06 2.35e-07  3.85e-02     0s\n",
      "  18  -1.38632570e+03 -1.59305718e+03  1.43e-06 1.30e-07  2.66e-02     0s\n",
      "  19  -1.41926524e+03 -1.50768565e+03  1.45e-07 1.33e-08  1.12e-02     0s\n",
      "  20  -1.43402605e+03 -1.47770620e+03  5.19e-08 4.82e-09  5.56e-03     0s\n",
      "  21  -1.44339566e+03 -1.46474515e+03  1.55e-08 1.57e-09  2.72e-03     0s\n",
      "  22  -1.44836327e+03 -1.45772629e+03  3.98e-09 5.94e-10  1.19e-03     0s\n",
      "  23  -1.45099103e+03 -1.45423722e+03  5.62e-10 7.51e-10  4.12e-04     0s\n",
      "  24  -1.45226550e+03 -1.45273002e+03  5.32e-11 9.31e-10  5.88e-05     0s\n",
      "  25  -1.45243086e+03 -1.45246183e+03  1.39e-12 7.05e-10  3.90e-06     0s\n",
      "  26  -1.45243895e+03 -1.45244096e+03  1.16e-12 4.95e-10  2.53e-07     0s\n",
      "  27  -1.45243932e+03 -1.45244040e+03  3.07e-12 2.77e-10  1.35e-07     0s\n",
      "  28  -1.45243969e+03 -1.45243983e+03  3.36e-12 6.74e-11  1.74e-08     0s\n",
      "  29  -1.45243973e+03 -1.45243975e+03  9.62e-12 6.74e-11  1.93e-09     0s\n",
      "  30  -1.45243974e+03 -1.45243974e+03  1.21e-11 1.16e-10  1.99e-10     0s\n",
      "\n",
      "Barrier solved model in 30 iterations and 0.18 seconds (0.17 work units)\n",
      "Optimal objective -1.45243974e+03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:42 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:42 AM: Optimal value: 1.452e+03\n",
      "(CVXPY) Nov 03 11:43:42 AM: Compilation took 3.256e-01 seconds\n",
      "(CVXPY) Nov 03 11:43:42 AM: Solver (including time spent in interface) took 3.516e-01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:42 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:43 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:43 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:43 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:43 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:43 AM: Compiling problem (target solver=GUROBI).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:43 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:43 AM: Finished problem compilation (took 2.751e-01 seconds).\n",
      "(CVXPY) Nov 03 11:43:43 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0x9abfe6d0\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-11, 2e+03]\n",
      "Presolve removed 30860 rows and 40049 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 7683 rows, 14406 columns, 33706 nonzeros\n",
      "Presolved model has 7855 quadratic objective terms\n",
      "Ordering time: 0.01s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.079e+04\n",
      " Factor NZ  : 1.126e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.815e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.93854277e+08 -4.03149131e+08  1.10e+04 1.00e+03  9.98e+05     0s\n",
      "   1   1.52951645e+08 -1.58387020e+08  4.42e+03 4.02e+02  5.12e+05     0s\n",
      "   2   1.80506097e+07 -2.15817043e+07  8.37e+02 7.61e+01  1.15e+05     0s\n",
      "   3  -3.15959118e+02 -3.11117418e+06  2.68e+01 2.44e+00  4.24e+03     0s\n",
      "   4  -1.33060958e+03 -1.73464324e+06  2.38e+00 2.16e-01  5.22e+02     0s\n",
      "   5  -3.75824656e+02 -1.13657398e+06  9.14e-01 8.31e-02  2.54e+02     0s\n",
      "   6   4.00753519e+02 -5.97227470e+05  2.91e-01 2.64e-02  1.03e+02     0s\n",
      "   7   9.86702525e+02 -1.71907983e+05  4.35e-02 3.95e-03  2.39e+01     0s\n",
      "   8   7.48140422e+02 -4.75343736e+04  1.11e-02 1.01e-03  6.37e+00     0s\n",
      "   9  -1.86139203e+02 -1.55675069e+04  1.20e-03 1.09e-04  1.97e+00     0s\n",
      "  10  -7.86974463e+02 -4.33807660e+03  1.70e-04 1.54e-05  4.51e-01     0s\n",
      "  11  -1.03229124e+03 -3.09184106e+03  8.01e-05 7.28e-06  2.62e-01     0s\n",
      "  12  -1.11250868e+03 -2.64924610e+03  4.18e-05 3.80e-06  1.96e-01     0s\n",
      "  13  -1.23747028e+03 -2.00453350e+03  1.62e-05 1.47e-06  9.79e-02     0s\n",
      "  14  -1.28913573e+03 -1.85976731e+03  9.32e-06 8.47e-07  7.30e-02     0s\n",
      "  15  -1.31459327e+03 -1.76725438e+03  5.39e-06 4.90e-07  5.80e-02     0s\n",
      "  16  -1.34900430e+03 -1.61401660e+03  2.33e-06 2.12e-07  3.40e-02     0s\n",
      "  17  -1.37464692e+03 -1.52650810e+03  9.75e-07 8.87e-08  1.95e-02     0s\n",
      "  18  -1.38901578e+03 -1.49034398e+03  4.60e-07 4.18e-08  1.30e-02     0s\n",
      "  19  -1.40820510e+03 -1.45333540e+03  8.86e-08 8.11e-09  5.75e-03     0s\n",
      "  20  -1.41855889e+03 -1.43378308e+03  1.68e-08 1.68e-09  1.94e-03     0s\n",
      "  21  -1.42354349e+03 -1.42798105e+03  1.35e-09 2.80e-10  5.61e-04     0s\n",
      "  22  -1.42519339e+03 -1.42604549e+03  2.77e-13 4.86e-10  1.07e-04     0s\n",
      "  23  -1.42549186e+03 -1.42568416e+03  4.25e-13 4.66e-10  2.42e-05     0s\n",
      "  24  -1.42555001e+03 -1.42558589e+03  8.16e-13 3.56e-10  4.51e-06     0s\n",
      "  25  -1.42556169e+03 -1.42556494e+03  5.85e-13 1.28e-10  4.07e-07     0s\n",
      "  26  -1.42556279e+03 -1.42556320e+03  2.65e-12 1.16e-10  5.16e-08     0s\n",
      "  27  -1.42556294e+03 -1.42556296e+03  8.35e-12 8.73e-11  2.45e-09     0s\n",
      "  28  -1.42556294e+03 -1.42556295e+03  2.33e-11 2.91e-11  1.68e-10     0s\n",
      "\n",
      "Barrier solved model in 28 iterations and 0.17 seconds (0.17 work units)\n",
      "Optimal objective -1.42556294e+03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:43 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:43 AM: Optimal value: 1.426e+03\n",
      "(CVXPY) Nov 03 11:43:43 AM: Compilation took 2.751e-01 seconds\n",
      "(CVXPY) Nov 03 11:43:43 AM: Solver (including time spent in interface) took 3.458e-01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:43 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:43 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:43 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:43 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:43 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:43 AM: Compiling problem (target solver=GUROBI).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:43 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Nov 03 11:43:43 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:44 AM: Finished problem compilation (took 2.648e-01 seconds).\n",
      "(CVXPY) Nov 03 11:43:44 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0x7a746e56\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-11, 2e+03]\n",
      "Presolve removed 30889 rows and 40075 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 7654 rows, 14380 columns, 33547 nonzeros\n",
      "Presolved model has 7842 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.064e+04\n",
      " Factor NZ  : 1.125e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.820e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.94964517e+08 -4.02188164e+08  1.10e+04 1.00e+03  9.99e+05     0s\n",
      "   1   1.40857691e+08 -1.45928051e+08  4.87e+03 4.42e+02  5.51e+05     0s\n",
      "   2   1.40098787e+07 -1.79060137e+07  8.64e+02 7.86e+01  1.20e+05     0s\n",
      "   3  -4.48460513e+03 -3.54138689e+06  1.37e+01 1.24e+00  2.38e+03     0s\n",
      "   4  -1.02608143e+03 -1.69259364e+06  1.82e+00 1.66e-01  4.34e+02     0s\n",
      "   5  -4.20310573e+02 -9.85390779e+05  6.68e-01 6.08e-02  1.93e+02     0s\n",
      "   6   1.93611246e+02 -5.29243866e+05  1.62e-01 1.47e-02  8.08e+01     0s\n",
      "   7   4.74975758e+02 -8.31598233e+04  1.02e-02 9.28e-04  1.09e+01     0s\n",
      "   8  -3.00351633e+01 -2.77485111e+04  2.22e-03 2.02e-04  3.56e+00     0s\n",
      "   9  -6.40365080e+02 -7.43291149e+03  2.73e-04 2.48e-05  8.66e-01     0s\n",
      "  10  -1.05716785e+03 -4.05866677e+03  8.77e-05 7.97e-06  3.83e-01     0s\n",
      "  11  -1.21516372e+03 -3.22100033e+03  2.94e-05 2.67e-06  2.56e-01     0s\n",
      "  12  -1.32750628e+03 -2.29498256e+03  1.12e-05 1.01e-06  1.24e-01     0s\n",
      "  13  -1.37290560e+03 -2.05306103e+03  6.64e-06 6.04e-07  8.70e-02     0s\n",
      "  14  -1.39215865e+03 -1.94370381e+03  4.70e-06 4.27e-07  7.07e-02     0s\n",
      "  15  -1.41550925e+03 -1.82784610e+03  3.13e-06 2.84e-07  5.29e-02     0s\n",
      "  16  -1.45303950e+03 -1.69564450e+03  9.06e-07 8.24e-08  3.10e-02     0s\n",
      "  17  -1.47486114e+03 -1.59825403e+03  2.26e-07 2.07e-08  1.57e-02     0s\n",
      "  18  -1.49396141e+03 -1.55442538e+03  7.39e-08 6.86e-09  7.72e-03     0s\n",
      "  19  -1.50730464e+03 -1.52505308e+03  6.50e-09 8.22e-10  2.25e-03     0s\n",
      "  20  -1.51067718e+03 -1.52117065e+03  1.62e-09 1.02e-09  1.33e-03     0s\n",
      "  21  -1.51365957e+03 -1.51711001e+03  4.94e-10 1.35e-09  4.38e-04     0s\n",
      "  22  -1.51483539e+03 -1.51577408e+03  7.61e-11 2.31e-09  1.19e-04     0s\n",
      "  23  -1.51508268e+03 -1.51546718e+03  1.69e-11 1.86e-09  4.86e-05     0s\n",
      "  24  -1.51522591e+03 -1.51528197e+03  1.94e-12 3.72e-09  7.07e-06     0s\n",
      "  25  -1.51524456e+03 -1.51524987e+03  9.88e-13 6.13e-10  6.69e-07     0s\n",
      "  26  -1.51524636e+03 -1.51524680e+03  2.08e-12 1.16e-10  5.52e-08     0s\n",
      "  27  -1.51524651e+03 -1.51524655e+03  2.80e-12 4.00e-11  5.13e-09     0s\n",
      "  28  -1.51524653e+03 -1.51524653e+03  8.10e-12 8.66e-12  3.10e-10     0s\n",
      "  29  -1.51524653e+03 -1.51524653e+03  1.35e-11 5.07e-12  6.25e-11     0s\n",
      "\n",
      "Barrier solved model in 29 iterations and 0.17 seconds (0.17 work units)\n",
      "Optimal objective -1.51524653e+03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:44 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:44 AM: Optimal value: 1.515e+03\n",
      "(CVXPY) Nov 03 11:43:44 AM: Compilation took 2.648e-01 seconds\n",
      "(CVXPY) Nov 03 11:43:44 AM: Solver (including time spent in interface) took 3.313e-01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:44 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:44 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:44 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:44 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:44 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:44 AM: Compiling problem (target solver=GUROBI).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:44 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Nov 03 11:43:44 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:44 AM: Finished problem compilation (took 2.638e-01 seconds).\n",
      "(CVXPY) Nov 03 11:43:44 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0xe93ee3ad\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-11, 2e+03]\n",
      "Presolve removed 30878 rows and 40057 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 7665 rows, 14398 columns, 33565 nonzeros\n",
      "Presolved model has 7851 quadratic objective terms\n",
      "Ordering time: 0.01s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.064e+04\n",
      " Factor NZ  : 1.112e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.780e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.95458228e+08 -4.02610377e+08  1.10e+04 1.00e+03  9.99e+05     0s\n",
      "   1   1.40553788e+08 -1.45555948e+08  4.86e+03 4.41e+02  5.50e+05     0s\n",
      "   2   1.42144136e+07 -1.80478184e+07  8.67e+02 7.88e+01  1.20e+05     0s\n",
      "   3  -3.95977286e+03 -3.47335620e+06  1.10e+01 1.00e+00  1.99e+03     0s\n",
      "   4  -7.72913890e+02 -1.56821291e+06  1.45e+00 1.32e-01  3.72e+02     0s\n",
      "   5  -3.07854270e+02 -1.00270320e+06  6.21e-01 5.65e-02  1.92e+02     0s\n",
      "   6   2.80199589e+02 -4.26649370e+05  1.08e-01 9.80e-03  6.21e+01     0s\n",
      "   7   4.11056267e+02 -5.79440509e+04  6.58e-03 5.98e-04  7.53e+00     0s\n",
      "   8  -8.15017772e+01 -2.97581049e+04  2.32e-03 2.11e-04  3.82e+00     0s\n",
      "   9  -7.65046844e+02 -6.50720350e+03  2.35e-04 2.14e-05  7.31e-01     0s\n",
      "  10  -1.07891569e+03 -3.74409019e+03  8.87e-05 8.06e-06  3.39e-01     0s\n",
      "  11  -1.23305899e+03 -2.63233302e+03  3.16e-05 2.87e-06  1.78e-01     0s\n",
      "  12  -1.32429636e+03 -2.17089850e+03  1.60e-05 1.46e-06  1.08e-01     0s\n",
      "  13  -1.36009057e+03 -2.01510686e+03  1.07e-05 9.70e-07  8.38e-02     0s\n",
      "  14  -1.37545075e+03 -1.93775019e+03  8.24e-06 7.49e-07  7.20e-02     0s\n",
      "  15  -1.40033564e+03 -1.82247900e+03  5.55e-06 5.05e-07  5.41e-02     0s\n",
      "  16  -1.43749903e+03 -1.70479663e+03  1.82e-06 1.66e-07  3.42e-02     0s\n",
      "  17  -1.46681595e+03 -1.57161372e+03  3.09e-07 2.81e-08  1.33e-02     0s\n",
      "  18  -1.47874468e+03 -1.54384566e+03  1.59e-07 1.45e-08  8.30e-03     0s\n",
      "  19  -1.49252462e+03 -1.51668154e+03  4.19e-08 3.90e-09  3.08e-03     0s\n",
      "  20  -1.49768073e+03 -1.50930033e+03  1.34e-08 1.40e-09  1.48e-03     0s\n",
      "  21  -1.50132922e+03 -1.50474486e+03  5.27e-11 4.66e-10  4.30e-04     0s\n",
      "  22  -1.50237019e+03 -1.50363241e+03  1.78e-11 9.38e-10  1.59e-04     0s\n",
      "  23  -1.50291141e+03 -1.50304854e+03  7.27e-13 1.86e-09  1.73e-05     0s\n",
      "  24  -1.50295399e+03 -1.50296483e+03  1.07e-12 1.52e-09  1.36e-06     0s\n",
      "  25  -1.50295792e+03 -1.50295869e+03  3.43e-12 4.73e-10  9.64e-08     0s\n",
      "  26  -1.50295810e+03 -1.50295836e+03  7.68e-12 4.66e-10  2.97e-08     0s\n",
      "  27  -1.50295817e+03 -1.50295825e+03  1.22e-11 4.66e-10  6.64e-09     0s\n",
      "  28  -1.50295818e+03 -1.50295822e+03  2.09e-11 4.66e-10  1.03e-09     0s\n",
      "  29  -1.50295818e+03 -1.50295822e+03  2.29e-11 4.58e-10  2.33e-10     0s\n",
      "  30  -1.50295818e+03 -1.50295822e+03  1.30e-11 4.73e-10  2.02e-11     0s\n",
      "\n",
      "Barrier solved model in 30 iterations and 0.17 seconds (0.17 work units)\n",
      "Optimal objective -1.50295818e+03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:45 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:45 AM: Optimal value: 1.503e+03\n",
      "(CVXPY) Nov 03 11:43:45 AM: Compilation took 2.638e-01 seconds\n",
      "(CVXPY) Nov 03 11:43:45 AM: Solver (including time spent in interface) took 3.354e-01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:45 AM: Your problem has 37055 variables, 21143 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 03 11:43:45 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Nov 03 11:43:45 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 03 11:43:45 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Nov 03 11:43:45 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Nov 03 11:43:45 AM: Compiling problem (target solver=GUROBI).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:45 AM: Reduction chain: FlipObjective -> CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> GUROBI\n",
      "(CVXPY) Nov 03 11:43:45 AM: Applying reduction FlipObjective\n",
      "(CVXPY) Nov 03 11:43:45 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Nov 03 11:43:45 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Nov 03 11:43:45 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Nov 03 11:43:45 AM: Applying reduction GUROBI\n",
      "(CVXPY) Nov 03 11:43:45 AM: Finished problem compilation (took 2.591e-01 seconds).\n",
      "(CVXPY) Nov 03 11:43:45 AM: Invoking solver GUROBI  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 7800X3D 8-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "QCPDual  1\n",
      "\n",
      "Academic license 2721691 - for non-commercial use only - registered to c7___@uwaterloo.ca\n",
      "Optimize a model with 38543 rows, 54455 columns and 124455 nonzeros\n",
      "Model fingerprint: 0x89654eb8\n",
      "Model has 17480 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+02]\n",
      "  Objective range  [2e-02, 2e+00]\n",
      "  QObjective range [7e-04, 4e-03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e-12, 2e+03]\n",
      "Presolve removed 30887 rows and 40085 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 7656 rows, 14370 columns, 33491 nonzeros\n",
      "Presolved model has 7837 quadratic objective terms\n",
      "Ordering time: 0.01s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.060e+04\n",
      " Factor NZ  : 1.129e+05 (roughly 10 MB of memory)\n",
      " Factor Ops : 1.831e+06 (less than 1 second per iteration)\n",
      " Threads    : 8\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.94922452e+08 -4.02187655e+08  1.10e+04 1.00e+03  9.99e+05     0s\n",
      "   1   1.41716096e+08 -1.46823129e+08  4.90e+03 4.45e+02  5.54e+05     0s\n",
      "   2   1.44500632e+07 -1.83990454e+07  8.80e+02 8.00e+01  1.22e+05     0s\n",
      "   3  -4.32515791e+03 -3.58701338e+06  1.41e+01 1.28e+00  2.45e+03     0s\n",
      "   4  -7.54945421e+02 -1.66747302e+06  1.62e+00 1.48e-01  4.08e+02     0s\n",
      "   5  -2.14048377e+02 -1.02608734e+06  6.65e-01 6.05e-02  2.00e+02     0s\n",
      "   6   4.50737594e+02 -5.53947158e+05  1.80e-01 1.63e-02  8.60e+01     0s\n",
      "   7   7.97000540e+02 -1.02647153e+05  1.48e-02 1.35e-03  1.36e+01     0s\n",
      "   8   2.55992379e+02 -3.44529800e+04  2.74e-03 2.50e-04  4.46e+00     0s\n",
      "   9  -3.41344374e+02 -1.09016856e+04  5.29e-04 4.81e-05  1.35e+00     0s\n",
      "  10  -9.23352288e+02 -3.57873836e+03  8.22e-05 7.47e-06  3.38e-01     0s\n",
      "  11  -1.05941856e+03 -2.82835312e+03  5.37e-05 4.88e-06  2.25e-01     0s\n",
      "  12  -1.14163381e+03 -2.42409909e+03  3.08e-05 2.80e-06  1.64e-01     0s\n",
      "  13  -1.25652350e+03 -1.95843597e+03  1.26e-05 1.15e-06  8.97e-02     0s\n",
      "  14  -1.29555291e+03 -1.88627630e+03  8.52e-06 7.74e-07  7.57e-02     0s\n",
      "  15  -1.32460251e+03 -1.80182726e+03  5.72e-06 5.20e-07  6.13e-02     0s\n",
      "  16  -1.35505449e+03 -1.67416589e+03  2.73e-06 2.48e-07  4.10e-02     0s\n",
      "  17  -1.36811522e+03 -1.62844679e+03  1.98e-06 1.80e-07  3.35e-02     0s\n",
      "  18  -1.39089582e+03 -1.55890944e+03  9.57e-07 8.71e-08  2.16e-02     0s\n",
      "  19  -1.41788607e+03 -1.48774374e+03  1.34e-07 1.22e-08  8.90e-03     0s\n",
      "  20  -1.43113910e+03 -1.46635074e+03  3.23e-08 3.16e-09  4.49e-03     0s\n",
      "  21  -1.43902193e+03 -1.45316555e+03  4.46e-09 7.97e-10  1.80e-03     0s\n",
      "  22  -1.44277490e+03 -1.44797269e+03  1.16e-09 5.37e-10  6.60e-04     0s\n",
      "  23  -1.44451490e+03 -1.44575712e+03  2.00e-10 6.98e-10  1.58e-04     0s\n",
      "  24  -1.44491966e+03 -1.44519622e+03  2.63e-11 9.10e-10  3.50e-05     0s\n",
      "  25  -1.44502066e+03 -1.44503965e+03  1.03e-12 6.98e-10  2.39e-06     0s\n",
      "  26  -1.44502661e+03 -1.44502814e+03  1.81e-12 2.34e-10  1.92e-07     0s\n",
      "  27  -1.44502716e+03 -1.44502729e+03  8.90e-12 1.60e-10  1.61e-08     0s\n",
      "  28  -1.44502720e+03 -1.44502723e+03  1.19e-11 1.52e-11  3.53e-09     0s\n",
      "  29  -1.44502721e+03 -1.44502721e+03  7.06e-11 1.09e-11  6.37e-10     0s\n",
      "  30  -1.44502721e+03 -1.44502721e+03  1.09e-11 1.46e-11  1.13e-10     0s\n",
      "\n",
      "Barrier solved model in 30 iterations and 0.17 seconds (0.17 work units)\n",
      "Optimal objective -1.44502721e+03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Nov 03 11:43:45 AM: Problem status: optimal\n",
      "(CVXPY) Nov 03 11:43:45 AM: Optimal value: 1.445e+03\n",
      "(CVXPY) Nov 03 11:43:45 AM: Compilation took 2.591e-01 seconds\n",
      "(CVXPY) Nov 03 11:43:45 AM: Solver (including time spent in interface) took 3.317e-01 seconds\n"
     ]
    }
   ],
   "source": [
    "Y = {}\n",
    "beta_np = np.full((S, C), 0.01, dtype=float)  \n",
    "\n",
    "for t0 in month_starts_test:\n",
    "    cases_t0 = scenario_cases_test[t0]\n",
    "    counts_t0 = scenario_counts_test[t0]\n",
    "    p_t, _ = build_p_and_d_for_t0_by_surgeon(\n",
    "        cases_t0, counts_t0, model, transform_fixed, C, mode_cat=mode_cat\n",
    "    )\n",
    "\n",
    "    p_t_np = p_t.detach().cpu().numpy()\n",
    "    Y_star, X_list, B_list, val = solve_with_SAA(\n",
    "        N, S, C, T, K,\n",
    "        spec_of_surgeon_np, U_s_np=U_np, r_per_min_c_np=r_np, G_sn_np=G_sn_np,\n",
    "        A_scenarios_np=A_scenarios,\n",
    "        p0_np=p_t_np,\n",
    "        beta_sc_np=beta_np,\n",
    "        rho=1e-3,\n",
    "        tau_nom_sc=tau_nom_sc,\n",
    "        Ymax=25,\n",
    "        surgeon_cap=1800,\n",
    "        verbose=True\n",
    "    )\n",
    "    Y[t0] = Y_star\n",
    "    Y_star_np = Y_star\n",
    "\n",
    "    t0_str = pd.Timestamp(t0).strftime(\"%Y-%m-%d\")\n",
    "    np.save(f\"Y_SPO_{t0_str}.npy\", Y_star_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b0d8790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff083bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c8db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6b201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e511f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f1b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250357f-6ea4-49f9-8c0d-c92169f3645a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Y = {}\n",
    "\n",
    "for t0 in month_starts_test:\n",
    "    print(t0)\n",
    "    cases_t0 = scenario_cases_test[t0]\n",
    "    counts_t0 = scenario_counts_test[t0]\n",
    "    p_t,_ = build_p_and_d_for_t0_by_surgeon(\n",
    "        cases_t0, counts_t0, model, transform_fixed, C, mode_cat=mode_cat\n",
    "    )\n",
    "\n",
    "    p_t_np = p_t.detach().cpu().numpy()\n",
    "    Y_star = solve_first_stage(p_t)\n",
    "    Y[t0] = Y_star\n",
    "    Y_star_np = Y_star.detach().cpu().numpy()\n",
    "    t0_str = pd.Timestamp(t0).strftime(\"%Y-%m-%d\")\n",
    "    np.save(f\"Y_SPO_{t0_str}.npy\", Y_star_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51714d-9a71-453a-891c-b50cc82195c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMH_Project",
   "language": "python",
   "name": "cmh_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
